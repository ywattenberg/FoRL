# === FoRL Envs ===
FoRLCartPole-v0:
  ent_coef: 1.5204787632094496e-05
  gae_lambda: 0.92
  gamma: 0.9
  learning_rate: 0.0005537992040750878
  n_envs: 8
  n_timesteps: !!float 5e5
  policy: "MlpPolicy"
  policy_kwargs: "dict(activation_fn=nn.Tanh)"

FoRLMountainCar-v0:
  normalize: true
  n_envs: 16
  n_timesteps: !!float 5e5
  policy: "MlpPolicy"
  ent_coef: 2.4668191625037606e-07
  gae_lambda: 1.0
  gamma: 0.99
  learning_rate: 7.208585642745669e-05
  max_grad_norm: 0.6
  n_steps: 8
  normalize_advantage: True
  use_rms_prop: True
  vf_coef: 0.6780248524458619
  policy_kwargs: "dict(activation_fn=nn.Tanh,  net_arch= dict(pi=[256, 256], vf=[256, 256]),  ortho_init=True)"

FoRLAcrobot-v0:
  normalize: true
  n_envs: 16
  n_timesteps: !!float 5e5
  policy: "MlpPolicy"
  ent_coef: 0.017588106778778027
  gae_lambda: 0.92
  gamma: 0.9999
  learning_rate: 0.002200109260848284
  max_grad_norm: 0.9
  n_steps: 32
  normalize_advantage: True
  use_rms_prop: True
  vf_coef: 0.32630339304488776
  policy_kwargs: "dict(activation_fn=nn.Tanh,  net_arch= dict(pi=[256, 256], vf=[256, 256]),  ortho_init=False)"

FoRLPendulum-v0:
  normalize: True
  n_envs: 8
  n_timesteps: !!float 5e5
  policy: "MlpPolicy"
  ent_coef: 0.002437595510900004
  gae_lambda: 0.95
  gamma: 0.95
  learning_rate: lin_0.00506420892135845
  max_grad_norm: 1
  n_steps: 8
  normalize_advantage: False
  use_rms_prop: True
  vf_coef: 0.9488118062280486
  policy_kwargs: "dict(activation_fn=nn.Tanh,  net_arch= dict(pi=[256, 256], vf=[256, 256]),  ortho_init=False)"

FoRLCartPoleRandomNormal-v0:
  n_envs: 8
  n_timesteps: !!float 5e5
  policy: "MlpPolicy"
  policy_kwargs: "dict(activation_fn=nn.ReLU)"
  ent_coef: 0.00926759533995833
  gae_lambda: 1.0
  gamma: 0.99
  learning_rate: lin_0.002074672910433195

FoRLMountainCarRandomNormal-v0:
  normalize: true
  n_envs: 16
  n_timesteps: !!float 5e5
  policy: "MlpPolicy"
  ent_coef: 1.5515893974798233e-06
  gae_lambda: 0.8
  gamma: 0.995
  learning_rate: 0.0002554232220658526
  max_grad_norm: 0.8
  n_steps: 32
  normalize_advantage: True
  use_rms_prop: False
  vf_coef: 0.5850292846769275
  policy_kwargs: "dict(activation_fn=nn.Tanh,  net_arch= dict(pi=[256, 256], vf=[256, 256]),  ortho_init=False)"

FoRLAcrobotRandomNormal-v0:
  normalize: true
  n_envs: 16
  n_timesteps: !!float 5e5
  policy: "MlpPolicy"
  ent_coef: 0.0731454571666543
  gae_lambda: 0.9
  gamma: 0.995
  learning_rate: lin_0.0012728070862257092
  max_grad_norm: 0.3
  n_steps: 256
  normalize_advantage: False
  use_rms_prop: True
  vf_coef: 0.1335521413528168
  policy_kwargs: "dict(activation_fn=nn.Tanh,  net_arch=dict(pi=[64, 64], vf=[64, 64]),  ortho_init=False)"

FoRLPendulumRandomNormal-v0:
  normalize: True
  n_envs: 8
  n_timesteps: !!float 5e5
  policy: "MlpPolicy"
  ent_coef: 0.002437595510900004
  gae_lambda: 0.95
  gamma: 0.95
  learning_rate: lin_0.00506420892135845
  max_grad_norm: 1
  n_steps: 8
  normalize_advantage: False
  use_rms_prop: True
  vf_coef: 0.9488118062280486
  policy_kwargs: "dict(activation_fn=nn.Tanh,  net_arch= dict(pi=[256, 256], vf=[256, 256]),  ortho_init=False)"

HalfCheetah-v3: &mujoco-defaults
  normalize: true
  n_timesteps: !!float 5e5
  policy: "MlpPolicy"

FoRLHalfCheetahRandomNormal-v0:
  <<: *mujoco-defaults
  ent_coef: 7.864649097734562e-05
  gae_lambda: 0.92
  gamma: 0.98
  learning_rate: lin_0.0006212613511916779
  max_grad_norm: 0.8
  n_steps: 64
  normalize_advantage: False
  use_rms_prop: True
  vf_coef: 0.19942249758119274
  policy_kwargs: "dict(activation_fn=nn.ReLU,  net_arch= dict(pi=[256, 256], vf=[256, 256]),  ortho_init=True)"

FoRLHalfCheetah-v0:
  <<: *mujoco-defaults
  ent_coef: 0.003344105960054444
  gae_lambda: 0.8
  gamma: 0.995
  learning_rate: lin_0.0010595855386866969
  max_grad_norm: 0.9
  n_steps: 16
  normalize_advantage: True
  use_rms_prop: True
  vf_coef: 0.922079200188717
  policy_kwargs: "dict(activation_fn=nn.ReLU,  net_arch= dict(pi=[256, 256], vf=[256, 256]),  ortho_init=True)"

FoRLHopper-v0:
  <<: *mujoco-defaults
  ent_coef: 0.0012864599456188115
  gae_lambda: 0.92
  gamma: 0.99
  learning_rate: lin_0.0002077761579708021
  max_grad_norm: 2
  n_steps: 16
  normalize_advantage: False
  use_rms_prop: True
  vf_coef: 0.39318426235124604
  policy_kwargs: "dict(activation_fn=nn.ReLU,  net_arch= dict(pi=[256, 256], vf=[256, 256]),  ortho_init=False)"

FoRLHopperRandomNormal-v0:
  <<: *mujoco-defaults
  ent_coef: 0.000835201539493523
  gae_lambda: 0.95
  gamma: 0.99
  learning_rate: 0.0025272290519501367
  max_grad_norm: 0.9
  n_steps: 8
  normalize_advantage: False
  use_rms_prop: True
  vf_coef: 0.013173660280475768
  policy_kwargs: "dict(activation_fn=nn.Tanh,  net_arch=dict(pi=[64, 64], vf=[64, 64]),  ortho_init=False)"
