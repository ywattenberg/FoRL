# === FoRL Environment Configurations ===
FoRLPendulumRandomNormal-v0:
  n_envs: 4
  n_timesteps: !!float 5e5
  policy: "MlpPolicy"
  n_steps: 1024
  gae_lambda: 0.95
  gamma: 0.9
  n_epochs: 10
  ent_coef: 0.0
  learning_rate: !!float 5e5
  clip_range: 0.2
  use_sde: True
  sde_sample_freq: 4

# Tuned
FoRLCartPoleRandomNormal-v0:
  n_envs: 8
  n_timesteps: !!float 5e5
  policy: "MlpPolicy"
  n_steps: 32
  batch_size: 256
  gae_lambda: 0.8
  gamma: 0.98
  n_epochs: 20
  ent_coef: 0.0
  learning_rate: lin_0.001
  clip_range: lin_0.2

FoRLMountainCarRandomNormal-v0:
  normalize: true
  n_envs: 16
  n_timesteps: !!float 5e5
  policy: "MlpPolicy"
  n_steps: 16
  gae_lambda: 0.98
  gamma: 0.99
  n_epochs: 4
  ent_coef: 0.0

FoRLAcrobotRandomNormal-v0:
  normalize: true
  n_envs: 16
  n_timesteps: !!float 5e5
  policy: "MlpPolicy"
  n_steps: 256
  gae_lambda: 0.94
  gamma: 0.99
  n_epochs: 4
  ent_coef: 0.0

FoRLPendulum-v0:
  n_envs: 4
  n_timesteps: !!float 5e5
  policy: "MlpPolicy"
  n_steps: 1024
  gae_lambda: 0.95
  gamma: 0.9
  n_epochs: 10
  ent_coef: 0.0
  learning_rate: !!float 1e-3
  clip_range: 0.2
  use_sde: True
  sde_sample_freq: 4

# Tuned
FoRLCartPole-v0:
  n_envs: 8
  n_timesteps: !!float 5e5
  policy: "MlpPolicy"
  n_steps: 32
  batch_size: 256
  gae_lambda: 0.8
  gamma: 0.98
  n_epochs: 20
  ent_coef: 0.0
  learning_rate: lin_0.001
  clip_range: lin_0.2

FoRLMountainCar-v0:
  normalize: true
  n_envs: 16
  n_timesteps: !!float 1e6
  policy: "MlpPolicy"
  n_steps: 16
  gae_lambda: 0.98
  gamma: 0.99
  n_epochs: 4
  ent_coef: 0.0

FoRLAcrobot-v0:
  normalize: true
  n_envs: 16
  n_timesteps: !!float 5e5
  policy: "MlpPolicy"
  n_steps: 256
  gae_lambda: 0.94
  gamma: 0.99
  n_epochs: 4
  ent_coef: 0.0

Ant-v3: &mujoco-defaults
  normalize: true
  n_timesteps: !!float 5e5
  policy: "MlpPolicy"

FoRLHalfCheetahRandomNormal-v0:
  <<: *mujoco-defaults

FoRLHalfCheetah-v0:
  <<: *mujoco-defaults

FoRLHopper-v0:
  <<: *mujoco-defaults

FoRLHopperRandomNormal-v0:
  <<: *mujoco-defaults
